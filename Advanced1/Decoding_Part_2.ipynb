{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10\n",
    "\n",
    "\n",
    "https://github.com/geifmany/cifar-vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cifar10vgg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8b1186e0f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcifar10vgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10vgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cifar10vgg'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from cifar10vgg import cifar10vgg\n",
    "from time import time\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def discrete_variable_score(y_true, y_predicted):    \n",
    "    return balanced_accuracy_score(y_true, y_predicted)\n",
    "\n",
    "def continuous_variable_score(y_true, y_predicted):\n",
    "    return pearsonr(y_true,y_predicted)[0]\n",
    "\n",
    "\n",
    "def extract_representations(model,samples):\n",
    "    inp = model.input                                           # input placeholder\n",
    "    outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "    functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
    "    layers_outs = functor([samples, 1.])\n",
    "    return layers_outs\n",
    "\n",
    "# create scorer\n",
    "my_func = make_scorer(discrete_variable_score,greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_test_int = y_test\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)    \n",
    "    return x_train, x_test, y_train, y_test, y_test_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, y_test_int = load_cifar10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cifar10vgg(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "samples = x_test[:n_samples,:,:,:]\n",
    "labels  = y_test[:n_samples,:]\n",
    "labels_int = y_test_int[:n_samples]\n",
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tin = time()\n",
    "predicted_x = model.predict(samples)\n",
    "print('Elapsed : {}'.format(time() - tin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.argmax(predicted_x,1) != np.argmax(labels,1)\n",
    "loss = sum(residuals)/len(residuals)\n",
    "print(\"the validation 0/1 loss is: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predicted_x[:10],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(labels[:10],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_outs = extract_representations(model.model, samples)\n",
    "layers_names = [l.name for l in model.model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(i, name, l.shape) for i, (name, l) in enumerate(zip(layers_names, layers_outs) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patiently individuate dropout and pooling layers indexes \n",
    "idx = [3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 52, 57, 59]\n",
    "selected_outs = [(layers_names[i],layers_outs[i]) for i in idx]\n",
    "\n",
    "# or use a nice list comprehension\n",
    "selected_outs = [(layers_names[i],layers_outs[i]) for i in range(len(layers_names)) \n",
    "                 if 'dropout' in layers_names[i] or 'pool' in layers_names[i]]\n",
    "\n",
    "selected_layers_labels = [l for (l,_) in selected_outs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = []\n",
    "Results = []\n",
    "Parameters = []\n",
    "\n",
    "\n",
    "Cs = np.power(10., np.arange(-3,3))\n",
    "#Cs = [0.01]\n",
    "\n",
    "# define grid of parameters\n",
    "param_grid = {'C' : Cs}\n",
    "nresampling = 10\n",
    "nfolds = 5\n",
    "nprocs = 1\n",
    "\n",
    "\n",
    "y = labels_int.ravel()\n",
    "\n",
    "for (name, representation) in tqdm(selected_outs):\n",
    "    \n",
    "    X = np.reshape(representation, (n_samples, -1))\n",
    "    \n",
    "    # preprocessing\n",
    "    #X = preprocessing.scale(X) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.1, random_state=None)\n",
    "    \n",
    "    clf_ = SVC(kernel='linear')\n",
    "    \n",
    "    grid_search = GridSearchCV(clf_, param_grid, \n",
    "                                scoring=my_func, \n",
    "                                cv=nfolds, \n",
    "                                n_jobs=nprocs, \n",
    "                                refit=True,\n",
    "                                return_train_score=True)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)    \n",
    "    \n",
    "    \n",
    "    Score.append(grid_search.best_score_)             \n",
    "    Results.append(grid_search.cv_results_)\n",
    "    Parameters.append(grid_search.best_params_['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 20\n",
    "ms = 20\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(range(len(selected_outs) ), Score, '-bo',markersize=ms) \n",
    "plt.xticks(range(len(selected_outs) ), \n",
    "           selected_layers_labels, \n",
    "           rotation='vertical',\n",
    "           fontsize=fs)\n",
    "\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.ylabel('balanced accuracy',fontsize=fs)\n",
    "plt.xlabel('layer',fontsize=fs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

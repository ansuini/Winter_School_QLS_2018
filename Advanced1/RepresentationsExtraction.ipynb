{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Representations from Deep Neural Networks\n",
    "\n",
    "\n",
    "One of the most basic and useful operations on a deep network is the extraction\n",
    "of representations in its hidden layers.\n",
    "\n",
    "The reason is that representations are in themselves a remarkable object of\n",
    "investigation. \n",
    "Representations are the encoding of the data at a given layer, and their categorical\n",
    "content can be decoded.\n",
    "The performance of this decoding can tell us how explicitly the categorical information is contained in the representation.\n",
    "In this exercise we will extract representations in hidden layers when an input is given. The way to do that in Keras is not exactly transparent, but we will show it.\n",
    "\n",
    "\n",
    "<img src=\"../NotebooksFigures/tikz41.png\" alt=\"drawing\" width=\"800\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import callbacks\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same code used for the training sessions\n",
    "\n",
    "(i_train, l_train), (i_test, l_test) = mnist.load_data()\n",
    "i_train, i_test = i_train/255.0, i_test/255.0\n",
    "i_train, i_test = i_train.astype(np.float32), i_test.astype(np.float32)\n",
    "i_train, i_test = np.expand_dims(i_train, 3), np.expand_dims(i_test, 3)\n",
    "l_train, l_test = to_categorical(l_train), to_categorical(l_test)\n",
    "\n",
    "i_validate = i_train[50000:, :, :, :]\n",
    "i_train = i_train[0:50000, :, :, :]\n",
    "l_validate = l_train[50000:, :]\n",
    "l_train = l_train[0:50000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction\n",
    "\n",
    "We build a multi-layer perceptron, similar to the one in the figure at the beginning of the notebook. We build the network in Keras but in a more 'pythonic'\n",
    "way, with respect to the training session, defining a network class and its methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 64\n",
    "n_epochs = 10\n",
    "learn_rate = 0.1\n",
    "history = {}\n",
    "tb_params = {\n",
    "    'write_images': True, 'histogram_freq': 5, \n",
    "    'write_grads': True, 'write_graph': False\n",
    "            }\n",
    "activation_fcn = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = layers.Input(shape=(28, 28, 1,), name='images')\n",
    "x = layers.Flatten()(img)\n",
    "x = layers.Dense(100, activation=activation_fcn, name='hidden1')(x)\n",
    "x = layers.Dense(100, activation=activation_fcn, name='hidden2')(x)\n",
    "x = layers.Dense(100, activation=activation_fcn, name='hidden3')(x)\n",
    "out = layers.Dense(10, activation='softmax', name='output')(x)\n",
    "model = Model(img, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "images (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 2.2570 - acc: 0.1749 - val_loss: 2.0579 - val_acc: 0.2246\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 1.3081 - acc: 0.5765 - val_loss: 0.7929 - val_acc: 0.7429\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.6937 - acc: 0.7907 - val_loss: 0.5519 - val_acc: 0.8509\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.5024 - acc: 0.8597 - val_loss: 0.4284 - val_acc: 0.8771\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.4046 - acc: 0.8842 - val_loss: 0.3521 - val_acc: 0.8981\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.3515 - acc: 0.8994 - val_loss: 0.3284 - val_acc: 0.9057\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.3140 - acc: 0.9112 - val_loss: 0.2764 - val_acc: 0.9227\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.2818 - acc: 0.9193 - val_loss: 0.2491 - val_acc: 0.9301\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.2554 - acc: 0.9270 - val_loss: 0.2275 - val_acc: 0.9365\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.2327 - acc: 0.9325 - val_loss: 0.2088 - val_acc: 0.9413\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.SGD(lr=learn_rate)\n",
    "model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "tb = callbacks.TensorBoard(log_dir=join('tb_data', 'fully_connected'), **tb_params)\n",
    "h = model.fit(\n",
    "    i_train, l_train, validation_data=(i_validate, l_validate), epochs=n_epochs,\n",
    "    batch_size=minibatch_size, callbacks=[tb]\n",
    "    )\n",
    "history['Fully Connected'] = h.history\n",
    "history['Fully Connected']['epoch'] = h.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representations extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = i_train.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "test = i_test[np.random.permutation(i_test.shape[0])[0:nsamples],:,:,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
    "\n",
    "\n",
    "layer_outs = functor([test, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Instantiates a Keras function.\n",
       "\n",
       "# Arguments\n",
       "    inputs: List of placeholder tensors.\n",
       "    outputs: List of output tensors.\n",
       "    updates: List of update ops.\n",
       "    **kwargs: Passed to `tf.Session.run`.\n",
       "\n",
       "# Returns\n",
       "    Output values as Numpy arrays.\n",
       "\n",
       "# Raises\n",
       "    ValueError: if invalid kwargs are passed in.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?K.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Returns the learning phase flag.\n",
       "\n",
       "The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
       "to be passed as input to any Keras function\n",
       "that uses a different behavior at train time and test time.\n",
       "\n",
       "# Returns\n",
       "    Learning phase (scalar integer tensor or Python integer).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?K.learning_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1)\n",
      "(1000, 784)\n",
      "(1000, 100)\n",
      "(1000, 100)\n",
      "(1000, 100)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "_ = [print(l.shape) for l in layer_outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94341296, 0.68029934, 0.18934679, ..., 0.5720547 , 0.8121603 ,\n",
       "        0.6126356 ],\n",
       "       [0.7269921 , 0.5324204 , 0.30694357, ..., 0.7420718 , 0.7657363 ,\n",
       "        0.4069131 ],\n",
       "       [0.13606167, 0.62172663, 0.19126253, ..., 0.89357895, 0.25269952,\n",
       "        0.742206  ],\n",
       "       ...,\n",
       "       [0.98225236, 0.7430345 , 0.05686154, ..., 0.99125755, 0.48475155,\n",
       "        0.2932695 ],\n",
       "       [0.75308293, 0.554284  , 0.23079765, ..., 0.8703133 , 0.5700442 ,\n",
       "        0.9495621 ],\n",
       "       [0.82203573, 0.61570245, 0.03745488, ..., 0.8826881 , 0.88168645,\n",
       "        0.95447797]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 1.6.0",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

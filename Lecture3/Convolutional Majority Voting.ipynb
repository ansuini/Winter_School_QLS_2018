{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3-4 Hands-on Session on Convolutional Networks\n",
    "\n",
    "\n",
    "- Authors : Eis Annavini, Alessio Ansuini\n",
    "- References : Neural Networks and Deep Learning, by Michael Nielsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import callbacks\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "import os.path as path\n",
    "import os\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from tqdm import tnrange\n",
    "from helpers import show_test\n",
    "\n",
    "jtplot.style(grid=False, ticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(mnist.load_data)\n",
    "\n",
    "(i_train, l_train), (i_test, l_test) = mnist.load_data()\n",
    "i_train, i_test = i_train/255.0, i_test/255.0\n",
    "i_train, i_test = i_train.astype(np.float32), i_test.astype(np.float32)\n",
    "i_train, i_test = np.expand_dims(i_train, 3), np.expand_dims(i_test, 3)\n",
    "l_train, l_test = to_categorical(l_train), to_categorical(l_test)\n",
    "i_validate = i_train[50000:, :, :, :]\n",
    "i_train = i_train[0:50000, :, :, :]\n",
    "l_validate = l_train[50000:, :]\n",
    "l_train = l_train[0:50000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 10\n",
    "n_epochs = 60\n",
    "learn_rate = 0.1\n",
    "history = {}\n",
    "tb_params = {\n",
    "    'write_images': True, 'histogram_freq': 5, \n",
    "    'write_grads': True, 'write_graph': False\n",
    "            }\n",
    "activation_fcn = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_mnist(i_train, l_train, transf = [(1, 0), (-1, 0), (0, 1), (0, -1)]):\n",
    "    i_enhanced = []\n",
    "    l_enhanced = []\n",
    "    for i in tnrange(i_train.shape[0]):\n",
    "        img = i_train[i, :, :, :]\n",
    "        label = l_train[i, :]\n",
    "        i_enhanced.append(img)\n",
    "        l_enhanced.append(label)\n",
    "        for shift in transf:\n",
    "            x = np.pad(img, ((abs(shift[0]), abs(shift[0])),\n",
    "                         (abs(shift[1]), abs(shift[1])), (0, 0)), 'constant')\n",
    "            x = np.roll(x, shift, (0, 1))\n",
    "            x = x[abs(shift[0]):(x.shape[0]-abs(shift[0])),\n",
    "                  abs(shift[1]):(x.shape[1]-abs(shift[1])), :]\n",
    "            i_enhanced.append(x)\n",
    "            l_enhanced.append(label)\n",
    "    i_enhanced = np.array(i_enhanced)\n",
    "    l_enhanced = np.array(l_enhanced)\n",
    "    perm_idx = np.random.permutation(i_enhanced.shape[0])\n",
    "    return i_enhanced[perm_idx, :, :, :], l_enhanced[perm_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f005bea94294470848890cd5a11e353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i_enh, l_enh = enhance_mnist(i_train, l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_fcn = 'relu'\n",
    "lmbd = 0.01\n",
    "learn_rate = 0.03\n",
    "minibatch_size = 100\n",
    "minimum_lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "250000/250000 [==============================] - 17s 70us/step - loss: 0.4537 - acc: 0.8498 - val_loss: 0.0626 - val_acc: 0.9819\n",
      "Epoch 2/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.1391 - acc: 0.9566 - val_loss: 0.0450 - val_acc: 0.9874\n",
      "Epoch 3/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0995 - acc: 0.9690 - val_loss: 0.0430 - val_acc: 0.9863\n",
      "Epoch 4/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0821 - acc: 0.9748 - val_loss: 0.0327 - val_acc: 0.9901\n",
      "Epoch 5/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0714 - acc: 0.9775 - val_loss: 0.0307 - val_acc: 0.9910\n",
      "Epoch 6/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0637 - acc: 0.9799 - val_loss: 0.0290 - val_acc: 0.9921\n",
      "Epoch 7/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0585 - acc: 0.9817 - val_loss: 0.0289 - val_acc: 0.9921\n",
      "Epoch 8/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0544 - acc: 0.9833 - val_loss: 0.0271 - val_acc: 0.9924\n",
      "Epoch 9/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0515 - acc: 0.9840 - val_loss: 0.0283 - val_acc: 0.9921\n",
      "Epoch 10/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0483 - acc: 0.9848 - val_loss: 0.0249 - val_acc: 0.9929\n",
      "Epoch 11/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0454 - acc: 0.9857 - val_loss: 0.0259 - val_acc: 0.9927\n",
      "Epoch 12/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0447 - acc: 0.9858 - val_loss: 0.0257 - val_acc: 0.9931\n",
      "Epoch 13/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0423 - acc: 0.9867 - val_loss: 0.0262 - val_acc: 0.9926\n",
      "Epoch 14/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0404 - acc: 0.9875 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 15/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0385 - acc: 0.9877 - val_loss: 0.0234 - val_acc: 0.9936\n",
      "Epoch 16/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0375 - acc: 0.9881 - val_loss: 0.0232 - val_acc: 0.9935\n",
      "Epoch 17/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0367 - acc: 0.9884 - val_loss: 0.0226 - val_acc: 0.9940\n",
      "Epoch 18/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0354 - acc: 0.9888 - val_loss: 0.0220 - val_acc: 0.9938\n",
      "Epoch 19/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0341 - acc: 0.9890 - val_loss: 0.0220 - val_acc: 0.9940\n",
      "Epoch 20/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0324 - acc: 0.9899 - val_loss: 0.0223 - val_acc: 0.9940\n",
      "Epoch 21/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0320 - acc: 0.9899 - val_loss: 0.0212 - val_acc: 0.9944\n",
      "Epoch 22/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0221 - val_acc: 0.9939\n",
      "Epoch 23/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0304 - acc: 0.9903 - val_loss: 0.0215 - val_acc: 0.9941\n",
      "Epoch 24/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0214 - val_acc: 0.9941\n",
      "Epoch 25/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0292 - acc: 0.9906 - val_loss: 0.0213 - val_acc: 0.9947\n",
      "Epoch 26/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0238 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00599999986588955.\n",
      "Epoch 27/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.0208 - val_acc: 0.9948\n",
      "Epoch 28/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0205 - val_acc: 0.9946\n",
      "Epoch 29/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0207 - val_acc: 0.9944\n",
      "Epoch 30/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0252 - acc: 0.9916 - val_loss: 0.0201 - val_acc: 0.9949\n",
      "Epoch 31/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0250 - acc: 0.9920 - val_loss: 0.0202 - val_acc: 0.9948\n",
      "Epoch 32/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.0209 - val_acc: 0.9946\n",
      "Epoch 33/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0204 - val_acc: 0.9947\n",
      "Epoch 34/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 35/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0196 - val_acc: 0.9950\n",
      "Epoch 36/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0203 - val_acc: 0.9946\n",
      "Epoch 37/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0203 - val_acc: 0.9946\n",
      "Epoch 38/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0229 - acc: 0.9929 - val_loss: 0.0202 - val_acc: 0.9945\n",
      "Epoch 39/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0230 - acc: 0.9925 - val_loss: 0.0196 - val_acc: 0.9949\n",
      "Epoch 40/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0203 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.001200000010430813.\n",
      "Epoch 41/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0230 - acc: 0.9927 - val_loss: 0.0199 - val_acc: 0.9949\n",
      "Epoch 42/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0197 - val_acc: 0.9948\n",
      "Epoch 43/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 44/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0229 - acc: 0.9927 - val_loss: 0.0198 - val_acc: 0.9948\n",
      "Epoch 45/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0199 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00024000001139938833.\n",
      "Epoch 46/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0226 - acc: 0.9927 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 47/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 48/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 49/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0197 - val_acc: 0.9950\n",
      "Epoch 50/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0221 - acc: 0.9928 - val_loss: 0.0198 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.8000001697801054e-05.\n",
      "Epoch 51/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0220 - acc: 0.9930 - val_loss: 0.0198 - val_acc: 0.9948\n",
      "Epoch 52/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0198 - val_acc: 0.9948\n",
      "Epoch 53/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0225 - acc: 0.9927 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 54/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0224 - acc: 0.9929 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 55/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0226 - acc: 0.9928 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 57/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0224 - acc: 0.9927 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 58/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 59/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 60/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 0.0219 - acc: 0.9931 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Train on 250000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3119 - acc: 0.1002 - val_loss: 2.2989 - val_acc: 0.1035\n",
      "Epoch 2/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3105 - acc: 0.1013 - val_loss: 2.2981 - val_acc: 0.1069\n",
      "Epoch 3/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3100 - acc: 0.1007 - val_loss: 2.2973 - val_acc: 0.1112\n",
      "Epoch 4/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.3093 - acc: 0.1021 - val_loss: 2.2966 - val_acc: 0.1169\n",
      "Epoch 5/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.3084 - acc: 0.1033 - val_loss: 2.2958 - val_acc: 0.1230\n",
      "Epoch 6/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3076 - acc: 0.1044 - val_loss: 2.2951 - val_acc: 0.1300\n",
      "Epoch 7/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3071 - acc: 0.1037 - val_loss: 2.2944 - val_acc: 0.1361\n",
      "Epoch 8/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.3064 - acc: 0.1047 - val_loss: 2.2937 - val_acc: 0.1421\n",
      "Epoch 9/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3061 - acc: 0.1044 - val_loss: 2.2931 - val_acc: 0.1503\n",
      "Epoch 10/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3047 - acc: 0.1072 - val_loss: 2.2924 - val_acc: 0.1571\n",
      "Epoch 11/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3047 - acc: 0.1058 - val_loss: 2.2918 - val_acc: 0.1654\n",
      "Epoch 12/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3038 - acc: 0.1073 - val_loss: 2.2912 - val_acc: 0.1737\n",
      "Epoch 13/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3029 - acc: 0.1092 - val_loss: 2.2905 - val_acc: 0.1857\n",
      "Epoch 14/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3024 - acc: 0.1083 - val_loss: 2.2899 - val_acc: 0.1944\n",
      "Epoch 15/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.3020 - acc: 0.1105 - val_loss: 2.2893 - val_acc: 0.2027\n",
      "Epoch 16/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3015 - acc: 0.1104 - val_loss: 2.2887 - val_acc: 0.2104\n",
      "Epoch 17/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3012 - acc: 0.1110 - val_loss: 2.2881 - val_acc: 0.2182\n",
      "Epoch 18/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3006 - acc: 0.1118 - val_loss: 2.2875 - val_acc: 0.2276\n",
      "Epoch 19/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.3001 - acc: 0.1130 - val_loss: 2.2869 - val_acc: 0.2351\n",
      "Epoch 20/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2999 - acc: 0.1125 - val_loss: 2.2864 - val_acc: 0.2424\n",
      "Epoch 21/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2992 - acc: 0.1145 - val_loss: 2.2858 - val_acc: 0.2505\n",
      "Epoch 22/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2984 - acc: 0.1150 - val_loss: 2.2852 - val_acc: 0.2574\n",
      "Epoch 23/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2985 - acc: 0.1147 - val_loss: 2.2846 - val_acc: 0.2640\n",
      "Epoch 24/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2977 - acc: 0.1168 - val_loss: 2.2841 - val_acc: 0.2708\n",
      "Epoch 25/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2973 - acc: 0.1170 - val_loss: 2.2835 - val_acc: 0.2755\n",
      "Epoch 26/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2971 - acc: 0.1177 - val_loss: 2.2829 - val_acc: 0.2818\n",
      "Epoch 27/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2961 - acc: 0.1190 - val_loss: 2.2823 - val_acc: 0.2872\n",
      "Epoch 28/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2961 - acc: 0.1178 - val_loss: 2.2818 - val_acc: 0.2929\n",
      "Epoch 29/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2958 - acc: 0.1202 - val_loss: 2.2812 - val_acc: 0.2989\n",
      "Epoch 30/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2947 - acc: 0.1211 - val_loss: 2.2806 - val_acc: 0.3059\n",
      "Epoch 31/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2946 - acc: 0.1216 - val_loss: 2.2800 - val_acc: 0.3118\n",
      "Epoch 32/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2944 - acc: 0.1220 - val_loss: 2.2795 - val_acc: 0.3176\n",
      "Epoch 33/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2935 - acc: 0.1240 - val_loss: 2.2789 - val_acc: 0.3249\n",
      "Epoch 34/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2932 - acc: 0.1240 - val_loss: 2.2783 - val_acc: 0.3318\n",
      "Epoch 35/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2928 - acc: 0.1249 - val_loss: 2.2777 - val_acc: 0.3390\n",
      "Epoch 36/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2927 - acc: 0.1247 - val_loss: 2.2771 - val_acc: 0.3458\n",
      "Epoch 37/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2920 - acc: 0.1270 - val_loss: 2.2765 - val_acc: 0.3538\n",
      "Epoch 38/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2917 - acc: 0.1274 - val_loss: 2.2758 - val_acc: 0.3626\n",
      "Epoch 39/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2909 - acc: 0.1282 - val_loss: 2.2752 - val_acc: 0.3707\n",
      "Epoch 40/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2906 - acc: 0.1301 - val_loss: 2.2746 - val_acc: 0.3790\n",
      "Epoch 41/60\n",
      "250000/250000 [==============================] - 15s 60us/step - loss: 2.2901 - acc: 0.1308 - val_loss: 2.2740 - val_acc: 0.3864\n",
      "Epoch 42/60\n",
      "250000/250000 [==============================] - 15s 59us/step - loss: 2.2899 - acc: 0.1313 - val_loss: 2.2733 - val_acc: 0.3950\n",
      "Epoch 43/60\n",
      "123800/250000 [=============>................] - ETA: 7s - loss: 2.2895 - acc: 0.1317"
     ]
    }
   ],
   "source": [
    "regularization = None#regularizers.l2(lmbd)\n",
    "\n",
    "models = []\n",
    "img = layers.Input(shape=(28,28,1,))\n",
    "for i in range(5):\n",
    "    x = layers.Conv2D(20, 5, activation=activation_fcn, kernel_regularizer=regularization)(img)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(40, 5, activation=activation_fcn, kernel_regularizer=regularization)(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(1000, activation=activation_fcn, kernel_regularizer=regularization)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(1000, activation=activation_fcn, kernel_regularizer=regularization)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    out = layers.Dense(10, activation='softmax')(x)\n",
    "    models.append(Model(img, out))\n",
    "opt = optimizers.SGD(lr=learn_rate)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=minimum_lr, verbose=True)\n",
    "out_layers = [model.output for model in models]\n",
    "\n",
    "for i in range(5):\n",
    "    model = models[i]\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    h = model.fit(\n",
    "        i_enh, l_enh, validation_data=(i_validate, l_validate), epochs=n_epochs,\n",
    "        batch_size=minibatch_size, callbacks=[reduce_lr]\n",
    "        )\n",
    "    model.save(path.join('models', \"convolutional_voting_{}.h5\".format(i)))\n",
    "\n",
    "avg_layer = layers.Average()(out_layers)\n",
    "avg_model = Model(img, avg_layer)\n",
    "avg_model.save(path.join('models', \"convolutional_voting_avg.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = load_model(path.join('models', 'convolutional_voting_avg.h5'))\n",
    "K.set_learning_phase(0)\n",
    "show_test(model, (i_test, l_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras with TensorFlow",
   "language": "python",
   "name": "keras-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansuini/.local/envs/tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)    \n",
    "    x_train, x_test = np.expand_dims(x_train, 3), np.expand_dims(x_test, 3)\n",
    "    y_test_int = y_test # keep labels in integer form\n",
    "    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test, y_test_int\n",
    "\n",
    "x_train, x_test, y_train, y_test, y_test_int = load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 validation samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test= x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built in data generation features of Keras\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range = 0.075,\n",
    "    height_shift_range = 0.075,\n",
    "    rotation_range = 12,\n",
    "    shear_range = 0.075,\n",
    "    zoom_range = 0.05,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 0\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1875/1875 [==============================] - 760s 405ms/step - loss: 0.1608 - acc: 0.9490 - val_loss: 0.0151 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00001: saving model to models/mnist_conv_deep_01.h5\n",
      "Epoch 2/12\n",
      "1875/1875 [==============================] - 770s 411ms/step - loss: 0.0392 - acc: 0.9883 - val_loss: 0.0137 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00002: saving model to models/mnist_conv_deep_02.h5\n",
      "Epoch 3/12\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 0.0290 - acc: 0.9911 - val_loss: 0.0131 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00003: saving model to models/mnist_conv_deep_03.h5\n",
      "Epoch 4/12\n",
      "1875/1875 [==============================] - 780s 416ms/step - loss: 0.0238 - acc: 0.9928 - val_loss: 0.0107 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00004: saving model to models/mnist_conv_deep_04.h5\n",
      "Epoch 5/12\n",
      "1875/1875 [==============================] - 785s 419ms/step - loss: 0.0204 - acc: 0.9938 - val_loss: 0.0117 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00005: saving model to models/mnist_conv_deep_05.h5\n",
      "Epoch 6/12\n",
      "1875/1875 [==============================] - 785s 419ms/step - loss: 0.0180 - acc: 0.9945 - val_loss: 0.0133 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00006: saving model to models/mnist_conv_deep_06.h5\n",
      "Epoch 7/12\n",
      "1875/1875 [==============================] - 786s 419ms/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0136 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00007: saving model to models/mnist_conv_deep_07.h5\n",
      "Epoch 8/12\n",
      "1875/1875 [==============================] - 788s 420ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00008: saving model to models/mnist_conv_deep_08.h5\n",
      "Epoch 9/12\n",
      "1875/1875 [==============================] - 799s 426ms/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0130 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00009: saving model to models/mnist_conv_deep_09.h5\n",
      "Epoch 10/12\n",
      "1875/1875 [==============================] - 790s 421ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0120 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00010: saving model to models/mnist_conv_deep_10.h5\n",
      "Epoch 11/12\n",
      "1875/1875 [==============================] - 788s 421ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0113 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00011: saving model to models/mnist_conv_deep_11.h5\n",
      "Epoch 12/12\n",
      "1875/1875 [==============================] - 792s 422ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0112 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00012: saving model to models/mnist_conv_deep_12.h5\n",
      "Validation loss: 0.011162111560954691\n",
      "Validation accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (5, 5),\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(Conv2D(32, kernel_size = (3, 3),\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5,\n",
    "                              patience = 2, min_lr = 0.0001)\n",
    "\n",
    "\n",
    "filepath='models/mnist_conv_deep_{epoch:02d}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False)\n",
    "\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train,\n",
    "                                  y_train,\n",
    "                                  batch_size = batch_size),\n",
    "                    epochs = epochs,\n",
    "                    steps_per_epoch = x_train.shape[0]/32,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (x_test, y_test),\n",
    "                    callbacks = [reduce_lr,checkpoint])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
